{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Excercise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential # type: ignore\n",
        "from tensorflow.keras.layers import Dense, Input # type: ignore\n",
        "from tensorflow.keras.datasets import mnist # type: ignore\n",
        "from tensorflow.keras.utils import to_categorical # type: ignore\n",
        "from tensorflow.keras.optimizers import Adam # type: ignore\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU detected, running on GPU.\n"
          ]
        }
      ],
      "source": [
        "if tf.config.list_physical_devices('GPU'):\n",
        "    tf.config.experimental.set_visible_devices(tf.config.list_physical_devices('GPU'), 'GPU')\n",
        "    print(\"GPU detected, running on GPU.\")\n",
        "else:\n",
        "    print(\"No GPU detected, running on CPU.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. loading the data\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], -1).astype(\"float32\") / 255\n",
        "x_test = x_test.reshape(x_test.shape[0], -1).astype(\"float32\") / 255\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. neural network\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(28 * 28,)))\n",
        "    model.add(Dense(128, activation=\"relu\"))\n",
        "    model.add(Dense(10, activation=\"softmax\"))\n",
        "    \n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(), metrics=[\"accuracy\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. fitness function\n",
        "\n",
        "def fitness(weights):\n",
        "    model = create_model()\n",
        "    model.set_weights(weights)\n",
        "    history = model.fit(x_train, y_train, \n",
        "                        epochs=1, batch_size=128, \n",
        "                        validation_data=(x_test, y_test),\n",
        "                        verbose=0)\n",
        "    acc = history.history[\"accuracy\"][-1]\n",
        "    loss = history.history[\"loss\"][-1]\n",
        "    val_acc = history.history[\"val_accuracy\"][-1]\n",
        "    val_loss = history.history[\"val_loss\"][-1]\n",
        "    \n",
        "    print(f\"Accuracy: {acc}, loss: {loss}, Validation accuracy: {val_acc}, Validation loss: {val_loss}\")\n",
        "    print()\n",
        "    return acc, loss, val_acc, val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. population initialization\n",
        "\n",
        "def init_population(pop_size, weight_shapes):\n",
        "    populations = []\n",
        "    for _ in range(pop_size):\n",
        "        individual = []\n",
        "        for shape in weight_shapes:\n",
        "            individual.append(np.random.randn(*shape))\n",
        "        populations.append(individual)\n",
        "    return populations\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. selection\n",
        "\n",
        "def select_parents(population, fitnesses):\n",
        "    sorted_population = sorted(zip(population, fitnesses), key=lambda x: x[1], reverse=True)\n",
        "    return[ind[0] for ind in sorted_population[:2]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. crossover\n",
        "\n",
        "def crossover(parent1, parent2):\n",
        "    child = []\n",
        "    for w1, w2 in zip(parent1, parent2):\n",
        "        crossover_point = random.randint(0, len(w1)-1)\n",
        "        child.append(np.concatenate((w1[:crossover_point], w2[crossover_point:])))\n",
        "    return child"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. mutation\n",
        "\n",
        "def mutation(individual, mutation_rate=0.1):\n",
        "    for i in range(len(individual)):\n",
        "        if random.random() < mutation_rate:\n",
        "            individual[i] += np.random.randn(*individual[i].shape) * 0.1\n",
        "    return individual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. evolution\n",
        "\n",
        "def algorithm(pop_size, weight_shapes, num_generations, mutation_rate):\n",
        "    population = init_population(pop_size, weight_shapes)\n",
        "    best_fitnesses = 0\n",
        "    best_individual = None\n",
        "\n",
        "    accuracy_list = []\n",
        "    losses_list = []\n",
        "    val_accuracy_list = []\n",
        "    val_losses_list = []\n",
        "\n",
        "    for generation in range(num_generations):\n",
        "        print(f\"Generation: {(generation+1)}/{num_generations}\")\n",
        "        fitnesses = [fitness(ind) for ind in population]\n",
        "        best_gen_individual = population[fitnesses.index(max(fitnesses, key=lambda x: x[0]))]\n",
        "        best_gen_acc, best_gen_loss, best_gen_val_acc, best_gen_val_loss = max(fitnesses, key=lambda x: x[0])\n",
        "\n",
        "        accuracy_list.append(best_gen_acc)\n",
        "        losses_list.append(best_gen_loss)\n",
        "        val_accuracy_list.append(best_gen_val_acc)\n",
        "        val_losses_list.append(best_gen_val_loss)\n",
        "\n",
        "\n",
        "        print(\"Best accuracy:\", best_gen_acc, \"Best loss:\", best_gen_loss)\n",
        "        print(\"Best val accuracy:\", best_gen_val_acc, \"Best val loss:\", best_gen_val_loss)\n",
        "        print()\n",
        "        \n",
        "        if best_gen_acc > best_fitnesses:\n",
        "            best_fitnesses = best_gen_acc\n",
        "            best_individual = best_gen_individual\n",
        "\n",
        "        # selection\n",
        "        parents = select_parents(population, [fit[0] for fit in fitnesses])\n",
        "\n",
        "        # crossover and mutation\n",
        "        next_generation = []\n",
        "        \n",
        "        for _ in range(pop_size//2):\n",
        "            parent1, parent2 = random.sample(parents, 2)\n",
        "            child1 = crossover(parent1, parent2)\n",
        "            child2 = crossover(parent2, parent1)\n",
        "\n",
        "\n",
        "            next_generation.append(mutation(child1, mutation_rate))\n",
        "            next_generation.append(mutation(child2, mutation_rate))\n",
        "        \n",
        "\n",
        "        # replace the population\n",
        "        population = next_generation\n",
        "        \n",
        "    return best_individual, best_fitnesses, accuracy_list, losses_list, val_accuracy_list, val_losses_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generation: 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1732730831.497862  102930 service.cc:148] XLA service 0x72b5100060f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1732730831.497894  102930 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce MX150, Compute Capability 6.1\n",
            "2024-11-27 20:07:11.522041: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1732730831.626309  102930 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
            "I0000 00:00:1732730832.685145  102930 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.604449987411499, loss: 18.057716369628906, Validation accuracy: 0.7932000160217285, Validation loss: 5.80794620513916\n",
            "\n",
            "Accuracy: 0.6146666407585144, loss: 15.505701065063477, Validation accuracy: 0.802299976348877, Validation loss: 5.2601189613342285\n",
            "\n",
            "Accuracy: 0.6081500053405762, loss: 17.89252471923828, Validation accuracy: 0.8030999898910522, Validation loss: 5.59536600112915\n",
            "\n",
            "Accuracy: 0.577750027179718, loss: 18.823225021362305, Validation accuracy: 0.7910000085830688, Validation loss: 5.677799224853516\n",
            "\n",
            "Accuracy: 0.5603500008583069, loss: 19.750391006469727, Validation accuracy: 0.7846999764442444, Validation loss: 5.850368976593018\n",
            "\n",
            "Accuracy: 0.6273166537284851, loss: 15.393304824829102, Validation accuracy: 0.8007000088691711, Validation loss: 5.415224075317383\n",
            "\n",
            "Accuracy: 0.593916654586792, loss: 18.700044631958008, Validation accuracy: 0.7832000255584717, Validation loss: 6.054754257202148\n",
            "\n",
            "Accuracy: 0.5974500179290771, loss: 20.440601348876953, Validation accuracy: 0.7871999740600586, Validation loss: 6.419949531555176\n",
            "\n",
            "Accuracy: 0.5846333503723145, loss: 19.12776756286621, Validation accuracy: 0.7954999804496765, Validation loss: 6.008228302001953\n",
            "\n",
            "Accuracy: 0.5886499881744385, loss: 18.688199996948242, Validation accuracy: 0.792900025844574, Validation loss: 5.936878681182861\n",
            "\n",
            "Best accuracy: 0.6273166537284851 Best loss: 15.393304824829102\n",
            "Best val accuracy: 0.8007000088691711 Best val loss: 5.415224075317383\n",
            "\n",
            "Generation: 2/5\n",
            "Accuracy: 0.5951499938964844, loss: 17.24208641052246, Validation accuracy: 0.7950000166893005, Validation loss: 5.812082290649414\n",
            "\n",
            "Accuracy: 0.5853166580200195, loss: 18.632671356201172, Validation accuracy: 0.7817000150680542, Validation loss: 5.7730841636657715\n",
            "\n",
            "Accuracy: 0.5977166891098022, loss: 17.430612564086914, Validation accuracy: 0.7893000245094299, Validation loss: 5.51991081237793\n",
            "\n",
            "Accuracy: 0.5889999866485596, loss: 19.1010684967041, Validation accuracy: 0.7985000014305115, Validation loss: 5.585444450378418\n",
            "\n",
            "Accuracy: 0.5964999794960022, loss: 18.52735710144043, Validation accuracy: 0.7901999950408936, Validation loss: 5.57943058013916\n",
            "\n",
            "Accuracy: 0.6015833616256714, loss: 19.212806701660156, Validation accuracy: 0.7918999791145325, Validation loss: 6.363148212432861\n",
            "\n",
            "Accuracy: 0.5827166438102722, loss: 19.174089431762695, Validation accuracy: 0.7961999773979187, Validation loss: 5.986144065856934\n",
            "\n",
            "Accuracy: 0.6050166487693787, loss: 17.198135375976562, Validation accuracy: 0.7924000024795532, Validation loss: 5.668827533721924\n",
            "\n",
            "Accuracy: 0.5972999930381775, loss: 17.264665603637695, Validation accuracy: 0.7886999845504761, Validation loss: 5.473182201385498\n",
            "\n",
            "Accuracy: 0.5930500030517578, loss: 18.826583862304688, Validation accuracy: 0.7914000153541565, Validation loss: 6.119444847106934\n",
            "\n",
            "Best accuracy: 0.6050166487693787 Best loss: 17.198135375976562\n",
            "Best val accuracy: 0.7924000024795532 Best val loss: 5.668827533721924\n",
            "\n",
            "Generation: 3/5\n",
            "Accuracy: 0.6056666374206543, loss: 16.918148040771484, Validation accuracy: 0.7918000221252441, Validation loss: 5.705296516418457\n",
            "\n",
            "Accuracy: 0.6101166605949402, loss: 16.465864181518555, Validation accuracy: 0.7982000112533569, Validation loss: 5.625202178955078\n",
            "\n",
            "Accuracy: 0.6100500226020813, loss: 18.503202438354492, Validation accuracy: 0.7937999963760376, Validation loss: 6.0607218742370605\n",
            "\n",
            "Accuracy: 0.5962499976158142, loss: 19.959545135498047, Validation accuracy: 0.7918000221252441, Validation loss: 6.213507652282715\n",
            "\n",
            "Accuracy: 0.595216691493988, loss: 19.98737335205078, Validation accuracy: 0.7968000173568726, Validation loss: 6.252863883972168\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 9. init and run the algorithm\n",
        "\n",
        "weight_shapes = [(784, 128), (128, ), (128, 10), (10, )]\n",
        "pop_size = 10\n",
        "num_generations = 5\n",
        "mutation_rate = 0.1\n",
        "\n",
        "best_individual, best_fitnesses, accuracy_list, losses_list, val_accuracy_list, val_losses_list = algorithm(pop_size, weight_shapes, num_generations, mutation_rate)\n",
        "\n",
        "print(\"Best individual:\", best_individual)\n",
        "print(\"Best fitness:\", best_fitnesses)\n",
        "\n",
        "plt.plot(accuracy_list)\n",
        "plt.plot(losses_list)\n",
        "plt.plot(val_accuracy_list)\n",
        "plt.plot(val_losses_list)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
